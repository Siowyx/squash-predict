---
title: "S&DS 425 Report - Squash Match Prediction"
author: "Yee Xian Siow"
date: "17 Dec 2023"
output:
  html_document:
    df_print: paged
  word_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo   =FALSE,      ## show or suppress the code
                      include=TRUE ,      ## show or suppress the output
                      message=FALSE,      ## omit messages generated by code
                      warning=FALSE,      ## omit warnings generated by code
                      comment=NA,         ## removes the ## from in front of outputs
                      fig.align="center", ## centers all figures
                      fig.height = 5,     ## set the default height
                      fig.weight = 5,     ## set the default width
                      fig.width = 8      ## set the default width
                      )
```

## Abstract

In this project, the objective is to forecast the outcomes of squash matches between two players by leveraging historical match results obtained from the Professional Squash Association website. The dataset includes information on previous seasons' match results, serving as the basis for training logistic regression models. The predictors for these models are derived from the current game scores, aiming to predict both game and match win probabilities. The predictions generated by the models closely align with the current PSA world rankings, showcasing the efficacy of logistic regression in capturing patterns and dynamics within squash match outcomes. To facilitate user interaction, a shiny app was developed, enabling users to easily predict match outcomes for various players. 

\newpage

## Introduction 

With the recent inclusion in the 2028 Olympic Games, Squash has garnered increasing attention, and predicting match outcomes is crucial for players, fans, and organizers alike. The motivation behind this project is to attempt to understand the squash match dynamics and develop predictive models for game and match outcomes. The challenge addressed is the inherent uncertainty in forecasting squash matches, considering the multifaceted nature of player skills and strategies.

  The dataset used in this project is sourced from the Professional Squash Association website, encompassing match results from previous seasons up to 26 Nov 2023. This comprehensive dataset includes player names, seasons, game scores, and match outcomes, forming the basis for training logistic regression models. The predictive variables are derived from the ongoing game scores, providing a dynamic and real-time approach to forecasting.

  The next section contains data extraction and cleaning, which describe the process of getting data from the Professional Squash Association website using the Selenium package. Then, the data exploration section reveals that some players only appeared in a few matches per season. In the data modeling section, we build several different logistic regression models for game and match win probabilities and found that the model predicting game win probabilities has the lowest AIC. The shiny section simply describe how the shiny app works. Then, we discuss the results of the model, including the top 20 coefficients for the players and the corresponding standard errors, in the results section. Finally, we discuss conclusions, limitations, and ideas for future work in the conclusions section.

\newpage

## Data Extraction and Cleaning

We extracted matches results from the Professional Squash Association website. First, we get the links to all completed tournaments results page from all seasons from the tournaments page (https://www.psaworldtour.com/tournaments/). The challenge for this step is that the html table that display the tournaments from the past seasons are generated dynamically, meaning the html code pulled from the scan() function will only have the links to tournaments in the current season. To solve this problem, we used the Selenium package, which allows us to interact with elements on the webpage. This way, we can select the specific season and extract the links for the corresponding tournaments. 

  Once we have the list of all links, we extracted the relevant tournament information and matches results from each link. To do this, we created a function to navigate the html table that contains all information. There were a lot of inconsistencies which results in a html table that has a different format from most that need to be checked. For example, some tournaments were only for one gender, tournaments have different number of players, some results were not recorded, some tournaments used a round robin format, some matches were best of 3 format, etc. The resulting data frame contains information on players names, gender, players tournament seeding, players countries, round (e.g. Final), match results (both games won and points won), tournament names, date of match, tournament location, tournament prize money tier, and season. Each row in the data frame represent a match. There were a total of 73498 matches results across more than 30 seasons extracted.

  Next, we did some data cleaning which includes date formatting, ensuring naming consistency for the players, and investigating NA entries. We simply remove the rows with NA scores because this just meant that the match results were not recorded on the website. For some of the NA entries in the player seed and country columns, we were able to cross check with other rows and fill in the correct values from another row with matching players and tournaments. 

  Additionally, there were some extra data processing steps before fitting the logistic regression models. The data were filtered based on seasons. Then, a player coefficient matrix is created, where each column represent a player and the entries were set to 1 if the player is player1, -1 if the player is player2, else 0. 

  For the first model, which predicts match win probability, the data frame used includes the player coefficient matrix and a column indicating if player1 wins the match. 

  For the second model, which predicts match win probability based on current game score, the data frame used includes the current number of games won by each player in addition to the player coefficient matrix and the player1 win indicator. We went through each game in a match in order, determine which player wins the game, and add a row representing the current number of games won by each player. There are as many rows as the number of games. For example, if player1 wins the first game and loses the next three games, the first row will be 1-0, second row will be 1-1, then 1-2 and 1-3. 

  For the third model, which predicts game win probability, the data frame used includes the player coefficient matrix and a column indicating if player1 wins the game. Similar to the second model, there are as many rows as the number of games in the data frame. To achieve this, we created columns indicating if player1 won each game and then apply pivot_longer() on the newly created columns. 
 
\newpage

## Data Exploration  

Before fitting the models, we checked the number of matches each player appeared in each season.

```{r}
library(dplyr)
library(ggplot2)
library(pubtheme)

df <- read.csv("data/cleaned_squash.csv")
df <- subset(df, select = -X)
seasons <- ("2023-2024")
df2 <- df %>%
    filter(season %in% seasons)
  
all_players <- unique(c(df2$player1, df2$player2))
n_matches_per_player <- rep(0, length(all_players))
for (i in 1:length(all_players)) {
  n_matches_per_player[i] <- nrow(df2[df2$player1 == all_players[i],]) + nrow(df2[df2$player2 == all_players[i],])
}

d <- data.frame(all_players, n_matches_per_player)
dg <- d %>%
  group_by(n_matches_per_player) %>%
  summarise(player_count = n())

g = ggplot(dg, aes(x=n_matches_per_player, y=player_count))+
  geom_col(width = 0.8)+ 
  labs(title    = "Player Count per Number of Matches Played in 2023-24 Season",
       x = 'Number of Matches Played in 2023-24 Season', 
       y = 'Player Count')
g %>%
  pub(type='bar')

```

The bar plot shows us that in 2023-24 season, there are a large number of players that only appear in a few matches. These players are most likely amateur players or players who are just started playing professionally. To safeguard the model from potential biases or predictions with high standard errors, we decided to code the players that only appeared in not more than 5 matches as "Others". We think that setting the threshold at 5 will be enough to eliminate potential biases. These "Others" players will be the reference players in the model. 

\newpage

## Data Modeling

The decision to utilize a logistic regression model for data modeling is appropriate, especially considering the binary nature of the predicted outcome. Logistic regression is well-suited for binary classification tasks, providing a clear and interpretable framework for analyzing the relationship between predictor variables and the binary response.

  We started with a simple logistic regression model that predicts player1 match win probability, which trained on the player coefficients matrix as the predictors and whether player1 wins the match as the response variable. The following plot shows the top 10 male players with the largest coefficients in the first model trained on data from the 2023-24 season.

```{r}
models1 <- readRDS("models/model2023-2024.rds")
model_m1 <- models1[[1]]
model_w1 <- models1[[2]]
models2 <- readRDS("models/model_dynamic2023-2024.rds")
model_m2 <- models2[[1]]
model_w2 <- models2[[2]]
models3 <- readRDS("models/model_game_win_2023-2024.rds")
model_m3 <- models3[[1]]
model_w3 <- models3[[2]]

dg1 = summary(model_m1)$coefficients %>% 
  as.data.frame() %>%
  rownames_to_column(var = 'var') %>%
  rename(coef=Estimate, se=`Std. Error`) %>%
  select(var, coef, se) %>%
  mutate(var = gsub('`', '', gsub('[(]|[)]', '', var))) %>%
  filter(var!='INTERCEPT') %>%
  arrange(desc(coef))

levels1 <- rev(dg1[1:10,]$var)
g1 = ggplot(dg1[1:10,], aes(x=coef, y=factor(dg1[1:10,]$var, levels = levels1)))+
  geom_segment(aes(x    = coef-se, 
                   xend = coef+se,
                   y    = factor(dg1[1:10,]$var, levels = levels1), 
                   yend = factor(dg1[1:10,]$var, levels = levels1)), color=pubred)+
  geom_point(color=pubred) +
  labs(title    = "Male Players with the Largest Coefficients for 2023-24 Season",
       subtitle = 'Model 1: Match Win Probability',
       x = 'Coefficients with 1 Standard Deviation', 
       y = NULL)  ## Optional. 

g1 %>% 
  pub(type = 'pop', 
      xlim = c(10, 25))
```

We can think of the coefficients as player ratings. These coefficients are in comparison to the reference player, "Others". The larger the coefficient, the larger the match win probability as predicted by the model. The top 10 players with the largest coefficient in the model is similar to the current PSA world rankings although the order is not exactly the same. 9 out 10 players of the top 10 players with the largest coefficient are currently top 10 in the current PSA world rankings, which is promising. 

Next, we wanted to incorporate the ability to predict match win probability given the current game score. So model 2 is another logistic regression model trained on the player coefficient matrix and the current number of games won by each player as the predictors and whether player1 wins the match as the response variable. A similar plot was made to look into the players coefficients.

```{r}
dg2 = summary(model_m2)$coefficients %>% 
  as.data.frame() %>%
  rownames_to_column(var = 'var') %>%
  rename(coef=Estimate, se=`Std. Error`) %>%
  select(var, coef, se) %>%
  mutate(var = gsub('`', '', gsub('[(]|[)]', '', var))) %>%
  filter(var!='INTERCEPT') %>%
  arrange(desc(coef))

levels2 <- rev(dg2[1:10,]$var)
g2 = ggplot(dg2[1:10,], aes(x=coef, y=factor(dg2[1:10,]$var, levels = levels2)))+
  geom_segment(aes(x    = coef-se, 
                   xend = coef+se,
                   y    = factor(dg2[1:10,]$var, levels = levels2), 
                   yend = factor(dg2[1:10,]$var, levels = levels2)), color=pubred)+
  geom_point(color=pubred) +
  labs(title    = "Male Players with the Largest Coefficients for 2023-24 Season",
       subtitle = 'Model 2: Match Win Probability with Current Scores',
       x = 'Coefficients with 1 Standard Deviation', 
       y = NULL)  ## Optional. 

g2 %>% 
  pub(type = 'pop', 
      xlim = c(10, 25))
```

The interpretation of the coefficient is similar to the previous model. The larger the coefficient, the larger the match win probability as predicted by the model. Although the order changed, the top 10 male players with the largest coefficient is also very similar to the previous model. However, we can see that the standard error of the player coefficients for model 2 is smaller than model 1. This means that the standard error of the match win probability prediction by model 2 will be be smaller than model 1. So we can be more confident about the prediction according to model 2. 

Lastly, we tried a different approach on predicting match win probability based on current game scores. We trained a logistic regression model to first predict the win probability for a single game. This model was trained on the player coefficient matrix as the predictors and whether player1 wins the game as the response variable. Again, a similar plot was made to look into the players coefficients.

```{r}
dg3 = summary(model_m3)$coefficients %>% 
  as.data.frame() %>%
  rownames_to_column(var = 'var') %>%
  rename(coef=Estimate, se=`Std. Error`) %>%
  select(var, coef, se) %>%
  mutate(var = gsub('`', '', gsub('[(]|[)]', '', var))) %>%
  filter(var!='INTERCEPT') %>%
  arrange(desc(coef))

levels3 <- rev(dg3[1:10,]$var)
g3 = ggplot(dg3[1:10,], aes(x=coef, y=factor(dg3[1:10,]$var, levels = levels3)))+
  geom_segment(aes(x    = coef-se, 
                   xend = coef+se,
                   y    = factor(dg3[1:10,]$var, levels = levels3), 
                   yend = factor(dg3[1:10,]$var, levels = levels3)), color=pubred)+
  geom_point(color=pubred) +
  labs(title    = "Male Players with the Largest Coefficients for 2023-24 Season",
       subtitle = 'Model 3: Game Win Probability',
       x = 'Coefficients with 1 Standard Deviation', 
       y = NULL)  ## Optional. 

g3 %>% 
  pub(type = 'pop', 
      xlim = c(5, 10))
```

The player coefficients can be interpreted the same way as before. The larger the coefficient, the larger the game win probability as predicted by the model. The list of top 10 male players with the largest coefficients for model 3 was again very similar to the previous models, and reflects the current top 10 players in the PSA world rankings. In model 3, the standard errors for the player coefficients are even smaller than in model 2. So we can be even more confident about the prediction according to model 3. 

To get the match win probability from the predicted game win probability, we first calculated the probabilities for the final game scores being "3-0", "3-1", and "3-2". Then, the match win probability is just the sum of the probabilities of all the different ways to win, which are "3-0", "3-1", and "3-2". These calculations were done by multiplying an initial state vector with the markov transition matrix. The initial state vector is a vector of length 15 to represent 15 different states of the match, "0-0", "1-0", "0-1", "2-0", "1-1", "0-2", "3-0", "2-1", "1-2", "0-3", "3-1", "2-2", "1-3", "3-2", "2-3". The initial state vector will be initialized as all zeros except one entry set as 1 to represent the current starting state. The markov transition matrix is constructed based on the game win probability. For example, if the game win probability is 0.6, the markov transition matrix looks like this:

```{r}
markov_transition_matrix <- function(win_prob) {
  lose_prob <- 1-win_prob
  
  scores <- factor(c("0-0", "1-0", "0-1", "2-0", "1-1", "0-2", "3-0", "2-1", "1-2", "0-3", 
                     "3-1", "2-2", "1-3", "3-2", "2-3"))
  m <- matrix(nrow = 15, ncol = 15)
  rownames(m) <- scores
  colnames(m) <- scores
  
  for (score in scores) {
    s <- unlist(strsplit(score, "-"))
    if (as.numeric(s[1]) == 3 | as.numeric(s[2]) == 3) next
    win_s <- paste0(as.character(as.numeric(s[1]) + 1), "-", s[2])
    lose_s <- paste0(s[1], "-", as.character(as.numeric(s[2]) + 1))
    m[score, win_s] <- win_prob
    m[score, lose_s] <- lose_prob
  }
  
  m["3-0", "3-0"] <- 1
  m["0-3", "0-3"] <- 1
  m["3-1", "3-1"] <- 1
  m["1-3", "1-3"] <- 1
  m["3-2", "3-2"] <- 1
  m["2-3", "2-3"] <- 1
  
  m[is.na(m)] <- 0
  
  return(m)
}
markov_transition_matrix(0.6)
```

If we want to get match win probability from "0-0", we would multiply an initial state vector with the first entry set to 1 with the markov transition matrix 5 times and get the sum of probabilities for "3-0", "3-1", and "3-2".  To get the match win probability based on the current game scores, we simply change the initial state vector, setting the corresponding entry to 1 to reflect the current game scores, and multiply it with the markov transition matrix as many times as the number of games left to play to a maximum of 5-game match. 

Since all three models were trained on different data, it was difficult compare them. In an effort to compare the models, we made a prediction for "Ali Farag" against "Paul Coll" based on all three models trained on data from season 2023-24 respectively.

```{r}
# check predicted match win probability and std err
p1 <- "Ali Farag"
p2 <- "Paul Coll"

# model 1
all_players <- gsub("`", "", names(coefficients(model_m1))[-1])
new_data <- data.frame(matrix(ncol = length(all_players), nrow = 1))
colnames(new_data) <- all_players
coef <- rep(0, length(all_players))
coef[which(all_players == p1)] <- 1
coef[which(all_players == p2)] <- -1
new_data[1,] <- coef
win_prob1 <- predict(model_m1, newdata = new_data, se.fit = T, type = "response")

# model 2
all_players <- gsub("`", "", names(coefficients(model_m2))[-1])
all_players <- all_players[all_players != "p1_sets_won" & all_players != "p2_sets_won"]
new_data <- data.frame(matrix(ncol = length(all_players) + 2, nrow = 1))
colnames(new_data) <- c(all_players, 'p1_sets_won', 'p2_sets_won')
coef <- rep(0, length(all_players))
coef[which(all_players == p1)] <- 1
coef[which(all_players == p2)] <- -1
new_data[1,] <- c(coef, 0, 0)
win_prob2 <- predict(model_m2, newdata = new_data, se.fit = T, type = "response")

# model 3
all_players <- gsub("`", "", names(coefficients(model_m3)))
all_players[1] <- "Others"
new_data <- data.frame(matrix(ncol = length(all_players), nrow = 1))
colnames(new_data) <- all_players
coef <- rep(0, length(all_players))
coef[which(all_players == p1)] <- 1
coef[which(all_players == p2)] <- -1
new_data[1,] <- coef
game_win_prob <- predict(model_m3, newdata = new_data, se.fit = T, type = "response")

# plot and compare
models <- c("Model 1", "Model 2", "Model 3*")
prob <- c(win_prob1$fit, win_prob2$fit, game_win_prob$fit)*100
low <- c(win_prob1$fit - win_prob1$se.fit, win_prob2$fit - win_prob2$se.fit, game_win_prob$fit - game_win_prob$se.fit)*100
high <- c(win_prob1$fit + win_prob1$se.fit, win_prob2$fit + win_prob2$se.fit, game_win_prob$fit + game_win_prob$se.fit)*100
dd <- data.frame(models, prob, low, high)

gg = ggplot(dd, aes(x=prob, y=factor(models, levels = rev(models))))+
  geom_segment(aes(x    = low, 
                   xend = high,
                   y    = factor(models, levels = rev(models)), 
                   yend = factor(models, levels = rev(models))), color=pubred)+
  geom_text(aes(x=prob, label=round(prob,2)), vjust=-1)+
  geom_text(aes(x=low,  label=round(low ,2)), hjust=1.1)+
  geom_text(aes(x=high, label=round(high,2)), hjust=-0.2)+
  geom_point(color=pubred) +
  labs(title    = "Ali Farg vs Paul Coll",
       subtitle = 'Match Win Probabilities with 1 Standard Deviation',
       captions = "*Model 3 predicts game win probability",
       x = 'Probability (%)', 
       y = NULL)  ## Optional. 

gg %>% 
  pub(type = 'pop', 
      xlim = c(50, 100))
```

The plot shows the match win probabilities as predicted by model 1 and model 2 and the game win probability as predicted by model 3. We can see that the match win probabilities for model 1 and model 2 are similar and much higher than the game win probability for model 3. However, the match win probability for model 3 derived from the game win probability of 65.88% is 77.83%, which is close to model 1 and model 2. Comparing the standard errors, model 2 clearly has a smaller standard error than model 2, and model 2 and model 3 seem to have similar standard errors. This is consistent with the player coefficients comparison where model 2 and model 3 have smaller standard errors for player coefficients. 

In choosing the final model, we considered the flexibility of the model, the complexity of the model, and the standard errors of the coefficients and predicted probabilities. Model 1 did not have flexibility of predicting match win probability based on the current scores and the standard errors of the coefficients and predicted probabilities were much larger. Model 2 was able to predict match win probability based on the current scores and the standard errors of the coefficients and predicted probabilities were smaller, but the model is slightly more complex with the addition of two predictors, the current number of games won by each player. Model 3 can predict match win probability based on the current scores, has smaller standard errors of the coefficients and predicted probabilities, and is a simple model with only the absolutely necessary player coefficients matrix as predictors. Additionally, with the match win probability being calculated with game win probability and markov transition matrix, we can make predictions specifically on the final scores of the match (e.g. 3-0, 1-3). Therefore, we chose to use model 3 as the final model. 

\newpage

## Shiny

After data modeling, we created a simple shiny app to facilitate user interaction with the model. The app allows users to toggle between men and women players, select different players, specify the current scores, and choose the number of previous seasons to be considered when making predictions. After all the selections have been made, a bar plot showing the match win probability and the probabilities for all the different possible final scores will be shown.

\newpage

## Results

The results is a bar plot showing the match win probability and the probabilities for all the different possible final scores. Below is a few examples:

```{r}
predict_game_win_prob <- function(model, p1, p2) {
  all_players <- gsub("`", "", names(coefficients(model)))
  all_players[1] <- "Others"
  
  new_data <- data.frame(matrix(ncol = length(all_players), nrow = 1))
  colnames(new_data) <- all_players
  
  coef <- rep(0, length(all_players))
  coef[which(all_players == p1)] <- 1
  coef[which(all_players == p2)] <- -1
  new_data[1,] <- coef
  
  win_prob <- predict(model, newdata = new_data, type = "response")
  
  return(win_prob[[1]])
}

predict_score_prob <- function(model, player1, player2, p1_set_won, p2_set_won) {
  win_prob <- predict_game_win_prob(model, player1, player2)
  m <- markov_transition_matrix(win_prob)
  
  score_prob <- rep(0, 15)
  score_prob[which(rownames(m) == paste0(p1_set_won, "-", p2_set_won))] = 1
  for (i in (p1_set_won+p2_set_won):5) {
    score_prob <- score_prob %*% m
  }
  return(score_prob)
}

probs <- predict_score_prob(model_m3, p1, p2, 0, 0)
scores <- factor(c("3-0", "3-1", "3-2", "2-3",  "1-3", "0-3"), 
                    levels = rev(c("3-0", "3-1", "3-2", "2-3",  "1-3", "0-3")))
probs <- c(probs[7], probs[11], probs[14], probs[15], probs[13], probs[10])
df <- data.frame(scores, probs)

title <- paste("Score Prediction for", p1, "vs", p2)
subtitle <- paste0("Match Win Probability = ", round(sum(df[1:3,]$probs)*100,2), "%")
g <- ggplot(df, aes(x=probs, y=scores)) + 
  geom_col(width = 0.8, fill = "#a6cbee") +
  geom_text(aes(label=paste0(round(probs*100,2), "%")), hjust=-0.1) +
  labs(title  = title,
     subtitle = subtitle,
     x = 'Probability (%)',
     y = "Scores") 
g %>%
  pub(type='bar')
```

This plot shows the match win probability for Ali Farag against Paul Coll and the probabilities for all the different possible final scores starting from 0-0.

```{r}
probs <- predict_score_prob(model_m3, p1, p2, 0, 1)
scores <- factor(c("3-0", "3-1", "3-2", "2-3",  "1-3", "0-3"), 
                    levels = rev(c("3-0", "3-1", "3-2", "2-3",  "1-3", "0-3")))
probs <- c(probs[7], probs[11], probs[14], probs[15], probs[13], probs[10])
df <- data.frame(scores, probs)

title <- paste("Score Prediction for", p1, "vs", p2)
subtitle <- paste0("Match Win Probability = ", round(sum(df[1:3,]$probs)*100,2), "%")
g <- ggplot(df, aes(x=probs, y=scores)) + 
  geom_col(width = 0.8, fill = "#a6cbee") +
  geom_text(aes(label=paste0(round(probs*100,2), "%")), hjust=-0.1) +
  labs(title  = title,
     subtitle = subtitle,
     x = 'Probability (%)',
     y = "Scores") 
g %>%
  pub(type='bar')
```

This plot shows the match win probability for Ali Farag against Paul Coll and the probabilities for all the different possible final scores starting from 0-1. We can see that the match win probability is now lower as expected and the probability for 3-0 is now 0% because it is impossible to win 3-0 after losing a game. 

```{r}
probs <- predict_score_prob(model_m3, p1, p2, 3, 1)
scores <- factor(c("3-0", "3-1", "3-2", "2-3",  "1-3", "0-3"), 
                    levels = rev(c("3-0", "3-1", "3-2", "2-3",  "1-3", "0-3")))
probs <- c(probs[7], probs[11], probs[14], probs[15], probs[13], probs[10])
df <- data.frame(scores, probs)

title <- paste("Score Prediction for", p1, "vs", p2)
subtitle <- paste0("Match Win Probability = ", round(sum(df[1:3,]$probs)*100,2), "%")
g <- ggplot(df, aes(x=probs, y=scores)) + 
  geom_col(width = 0.8, fill = "#a6cbee") +
  geom_text(aes(label=paste0(round(probs*100,2), "%")), hjust=-0.1) +
  labs(title  = title,
     subtitle = subtitle,
     x = 'Probability (%)',
     y = "Scores") 
g %>%
  pub(type='bar')
```

This plot shows the match win probability for Ali Farag against Paul Coll and the probabilities for all the different possible final scores starting from 3-1. We can see that the match win probability is now 100% because the match has already been won 3-1. Also, the probability for the final scores to be 3-1 is 100% and all other final scores has 0% probability as expected. 

\newpage

## Conclusions and Future Work

Although the predictions made by our final model is reasonable and closely reflect the current PSA world rankings, there are some limitations and assumptions made by the model. First of all the model is assuming independence between individual games. This helps keeping the model simple, but it is possible that there is some relationships between games that our model failed to capture. For example, I can imagine that the first game and the fifth match deciding game will have different game win probability for different players or against different players. For a player who is known for their durability and mental toughness, they will have a much higher game win probability in the fifth game. Also, in this case, the duration of the match will probably be a good predictor. 

One major issue about our model is that the game win probability prediction is not consistent. For example, if the game win probability for player A as player1 and player B as player2 is prob1 and the game win probability for player B as player1 and player A as player2 is prob2, prob1 + prob2 is not equal to 1. This is problematic because it is impossible for the probabilities to sum up to more than 1. This needs to be the first thing to be looked at closely for future iterations of the model.

We could also try to include more predictors to improve our model. In the data pulled from the PSA website, we actually have a lot of information that we did not use in the model. A few variables that I think might be worth trying to include in the model are round and prize money tier. Round can be useful because players might play differently in first round as compared to final for example. It can be due to nerves or fatigue from previous rounds. For prize money tier, maybe players try much harder in the world championships. The date of match can also be used to capture the amount of rest players had in between matches. If we can get the players biometric data, we could also include them in our model especially age. These additional predictors do not guarantee an enhancement of the model, but it might be worth considering.

Currently, the data was pulled up until 26 Nov 2023. We could implement a function that automatically check and update the data daily. Also, it will be really cool if we could find a way to incorporate live scores and predicting match win probabilities live. It will involve pulling data from https://www.psaworldtour.com/live/, which is dynamically generated. We could try to use Selenium again. Moreover, after having a good model that predicts based on current game scores, we could attempt to build a model that predicts based on current point scores. It will undoubtedly be complicated and difficult to build a good model that predicts based on current point scores, but it is definitely interesting to try in the future.

Lastly, we can spend more time making the shiny app interface more attractive to users.









 
